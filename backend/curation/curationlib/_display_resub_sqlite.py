from sac_resubmission_records_sqlite import fetch_sac_resubmission_records_sqlite
from generate_resubmission_clusters import generate_clusters_from_records
import argparse

from export_resubmission_clusters import (
    export_sets_as_text_tables,
    export_sets_as_csv,
    export_sets_as_markdown,
    export_mailmerge,
)


from datetime import datetime


def main(args):
    sacked = fetch_sac_resubmission_records_sqlite(args.audit_year, args.sqlite)
    sorted_sets = generate_clusters_from_records(sacked, args.audit_year, True)

    export_sets_as_text_tables(args.audit_year, sorted_sets, noisy=False)
    export_sets_as_csv(args.audit_year, sorted_sets, noisy=False)
    export_sets_as_markdown(args.audit_year, sorted_sets, noisy=False)
    export_mailmerge(args.audit_year, sorted_sets, noisy=False)


# Takes the name of an SQLite database like that generated by
# https://github.com/jadudm/fac-archive
# and uses it to then generate "fake" SAC records.
# (These are records with just enough data to be able to be
# used in the clustering algorithm.) The data is pulled from
# live/published data from the FAC, and therefore is accurate
# interms of what is live/in-production. Instead of using the SAC, it
# uses the disseminated data (indirectly).
if __name__ in "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("sqlite")
    parser.add_argument("audit_year")
    args = parser.parse_args()
    main(args)
